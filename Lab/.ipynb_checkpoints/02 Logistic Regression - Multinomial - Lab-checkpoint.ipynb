{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rising-budapest",
   "metadata": {},
   "source": [
    "### === Task ===\n",
    "\n",
    "1. With the iris data given in class, implement train_test_split from scratch.\n",
    "\n",
    "2. Put everything into a class called LogisticRegression, this class should allow you choose any of the training methods you'd like including \"batch\", \"minibatch\" and \"sto\". However, if the input method is not one of the three, it should \"raise ValueError\".\n",
    "\n",
    "3. Calculate time taken to fit your models using different training methods.\n",
    "\n",
    "4. Perform a classification on the dataset using all 3 methods and also show what happens if your defined training method is not either \"batch\", \"minibatch\" or \"sto\". Make sure to plot the training losses.\n",
    "\n",
    "5. Simply, use classification_report from sklearn.metrics to evaluate your models.\n",
    "\n",
    "6. Discuss your results ie. training losses of the three methods and time taken to fit models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "curious-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Step 1: Prepare data\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, 2:]  # we only take the first two features.\n",
    "y = iris.target  #now our y is three classes thus require multinomial\n",
    "\n",
    "# feature scaling helps improve reach convergence faster\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# add intercept to our X\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train   = np.concatenate((intercept, X_train), axis=1)  #add intercept\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "X_test    = np.concatenate((intercept, X_test), axis=1)  #add intercept\n",
    "\n",
    "# make sure our y is in the shape of (m, k)\n",
    "# we will convert our output vector in \n",
    "# matrix where no. of columns is equal to the no. of classes. \n",
    "# The values in the matrix will be 0 or 1. For instance the rows \n",
    "# where we have output 2 the column 2 will contain 1 and the rest are all 0.\n",
    "# in simple words, y will be of shape (m, k)\n",
    "k = len(set(y))  # no. of class  (can also use np.unique)\n",
    "m = X_train.shape[0]  # no.of samples\n",
    "n = X_train.shape[1]  # no. of features\n",
    "y_train_encoded = np.zeros((m, k))\n",
    "for each_class in range(k):\n",
    "    cond = y_train==each_class\n",
    "    y_train_encoded[np.where(cond), each_class] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "certified-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y):\n",
    "    y = np.array(y)\n",
    "\n",
    "    m = y.shape[0]\n",
    "\n",
    "    y_one_hotted = np.zeros((m, k))\n",
    "\n",
    "    for i, label in enumerate(y):\n",
    "        y_one_hotted[i, label ] = 1\n",
    "\n",
    "    return y_one_hotted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-toyota",
   "metadata": {},
   "source": [
    "# With the iris data given in class, implement train_test_split from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "psychological-reason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 2) (22, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_test_split(X, y, test_size=0.15):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "\n",
    "    m = X.shape[0]\n",
    "    indices = np.arange(m)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split_index = round(m * test_size)\n",
    "\n",
    "    train_indices, test_indices = indices[split_index:], indices[:split_index]\n",
    "\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assumed-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Fit your data\n",
    "\n",
    "def logistic_regression_GD(X, y, k, n, max_iter=1000):\n",
    "    '''\n",
    "    Inputs: \n",
    "        X shape: (m, n)\n",
    "        w shape: (n, k)\n",
    "    '''\n",
    "    w = np.random.rand(n, k)\n",
    "    l_rate = 0.01\n",
    "    for i in range(max_iter):\n",
    "        cost, grad =  gradient(X, y, w)\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Cost at iteration {i}\", cost)\n",
    "        w = w - l_rate * grad\n",
    "    return w, i\n",
    "\n",
    "# for those who tend to feel overwhelmed with lots of code\n",
    "# I recommend you to write each part of the code separately as function\n",
    "# it helps!\n",
    "def gradient(X, y, w):\n",
    "    m = X.shape[0]\n",
    "    h = h_theta(X, w)\n",
    "    cost = - np.sum(y*np.log(h)) / m\n",
    "    error = h - y\n",
    "    grad = softmax_grad(X, error)\n",
    "    return cost, grad\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "\n",
    "def softmax_grad(X, error):\n",
    "    return  X.T @ error\n",
    "        \n",
    "def h_theta(X, w):\n",
    "    '''\n",
    "    Input:\n",
    "        X shape: (m, n)\n",
    "        w shape: (n, k)\n",
    "    Returns:\n",
    "        yhat shape: (m, k)\n",
    "    '''\n",
    "    return softmax(X @ w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-scottish",
   "metadata": {},
   "source": [
    "# Put everything into a class called LogisticRegression, this class should allow you choose any of the training methods you'd like including \"batch\", \"minibatch\" and \"sto\". However, if the input method is not one of the three, it should \"raise ValueError\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "basic-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, method='batch', batch_size=None, learning_rate=0.0001, max_iter=5000, verbose=True):\n",
    "        self.method = method\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        valid_methods = [\"batch\", \"minibatch\", \"sto\"]\n",
    "        if method not in valid_methods:\n",
    "            raise ValueError(f'method must be one of {valid_methods}')\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        self.losses = []\n",
    "        \n",
    "        m = X.shape[0]\n",
    "        n = X.shape[1]\n",
    "        \n",
    "        k = len(np.unique(y))\n",
    "        \n",
    "        y = one_hot(y)\n",
    "        \n",
    "        self.w = np.random.rand(n, k)\n",
    "        old_loss = np.inf\n",
    "        \n",
    "        if self.method == 'batch' and self.batch_size == None:\n",
    "            self.batch_size = m # using whole training samples\n",
    "        elif self.method == 'sto' and self.batch_size == None:\n",
    "            self.batch_size = 1 # using 1 training sample\n",
    "            \n",
    "        step_size = math.ceil(m / self.batch_size)\n",
    "        \n",
    "        start = time.time()\n",
    "        for i in range(self.max_iter):\n",
    "            for step in range(step_size):\n",
    "                X_batch = X[step * self.batch_size: step * self.batch_size + self.batch_size]\n",
    "                y_batch = y[step * self.batch_size: step * self.batch_size + self.batch_size]\n",
    "                assert len(X_batch == self.batch_size)\n",
    "                cost, grad =  gradient(X_batch, y_batch, self.w )\n",
    "                self.losses.append(cost)\n",
    "\n",
    "                self.w = self.w - self.learning_rate * grad\n",
    "                \n",
    "            if i %1000 == 0 and self.verbose:\n",
    "                print(f'epoch {i}: cost {cost}')\n",
    "\n",
    "        end = time.time()\n",
    "        print('Time taken', end - start, 'second(s)\\n')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_predicted = h_theta(X, self.w)\n",
    "        return np.argmax(y_predicted, axis=1)\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.figure()\n",
    "        display(plt.plot(self.losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-merchandise",
   "metadata": {},
   "source": [
    "# Calculate time taken to fit your models using different training methods.\n",
    "# Perform a classification on the dataset using all 3 methods and also show what happens if your defined training method is not either \"batch\", \"minibatch\" or \"sto\". Make sure to plot the training losses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "lesser-buffer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch\n",
      "epoch 0: cost 1.1815575911247542\n",
      "epoch 1000: cost 0.08521636259514787\n",
      "epoch 2000: cost 0.08200398314794316\n",
      "epoch 3000: cost 0.08121636492562338\n",
      "epoch 4000: cost 0.08090983233808015\n",
      "Time taken 0.4349997043609619 second(s)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26439f45370>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini-Batch\n",
      "epoch 0: cost 0.6540296818726389\n",
      "epoch 1000: cost 0.009702322672441758\n",
      "epoch 2000: cost 0.005669323820414332\n",
      "epoch 3000: cost 0.004238350430871388\n",
      "epoch 4000: cost 0.0035290264816117867\n",
      "Time taken 1.1540207862854004 second(s)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2643b2e8370>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic\n",
      "epoch 0: cost 0.623578037381782\n",
      "epoch 1000: cost 0.03625959558051261\n",
      "epoch 2000: cost 0.02265701227899437\n",
      "epoch 3000: cost 0.018496656673317416\n",
      "epoch 4000: cost 0.016716010033674532\n",
      "Time taken 25.094998359680176 second(s)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2643b6403a0>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print('Batch')\n",
    "cls = LogisticRegression(learning_rate=0.01, max_iter=5000)\n",
    "cls.fit(X_train, y_train)\n",
    "cls.plot_loss()\n",
    "\n",
    "print('Mini-Batch')\n",
    "cls = LogisticRegression(learning_rate=0.01, max_iter=5000, method='minibatch', batch_size=32)\n",
    "cls.fit(X_train, y_train)\n",
    "cls.plot_loss()\n",
    "\n",
    "print('Stochastic')\n",
    "cls = LogisticRegression(learning_rate=0.01, max_iter=5000, method='sto')\n",
    "cls.fit(X_train, y_train)\n",
    "cls.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "automated-controversy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input invalid method\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "method must be one of ['batch', 'minibatch', 'sto']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-243-504898f4bf31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input invalid method'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hello?'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-238-454a66d76ff2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, method, batch_size, learning_rate, max_iter, verbose)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mvalid_methods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"batch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"minibatch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sto\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_methods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'method must be one of {valid_methods}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: method must be one of ['batch', 'minibatch', 'sto']"
     ]
    }
   ],
   "source": [
    "print('input invalid method')\n",
    "cls = LogisticRegression(learning_rate=0.01, max_iter=5000, method='hello?')\n",
    "cls.fit(X_train, y_train)\n",
    "cls.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-lotus",
   "metadata": {},
   "source": [
    "# Simply, use classification_report from sklearn.metrics to evaluate your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "constant-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch\n",
      "Time taken 0.4239985942840576 second(s)\n",
      "\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.94      1.00      0.97        16\n",
      "           2       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Mini-Batch\n",
      "Time taken 1.1514816284179688 second(s)\n",
      "\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.94      1.00      0.97        16\n",
      "           2       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Stochastic\n",
      "Time taken 24.322064876556396 second(s)\n",
      "\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.94      1.00      0.97        16\n",
      "           2       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train   = np.concatenate((intercept, X_train), axis=1)  #add intercept\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "X_test    = np.concatenate((intercept, X_test), axis=1)  #add intercept\n",
    "\n",
    "\n",
    "print('Batch')\n",
    "cls = LogisticRegression(learning_rate=0.001, max_iter=5000, method='batch', verbose=False)\n",
    "cls.fit(X_train, y_train)\n",
    "yhat = cls.predict(X_test)\n",
    "print(\"Report: \", classification_report(y_test, yhat))\n",
    "\n",
    "print('Mini-Batch')\n",
    "cls = LogisticRegression(learning_rate=0.01, max_iter=5000, method='minibatch', batch_size=32, verbose=False)\n",
    "cls.fit(X_train, y_train)\n",
    "yhat = cls.predict(X_test)\n",
    "print(\"Report: \", classification_report(y_test, yhat))\n",
    "\n",
    "print('Stochastic')\n",
    "cls = LogisticRegression(learning_rate=0.01, max_iter=5000, method='sto', verbose=False)\n",
    "cls.fit(X_train, y_train)\n",
    "yhat = cls.predict(X_test)\n",
    "print(\"Report: \", classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-reader",
   "metadata": {},
   "source": [
    "# Discuss your results ie. training losses of the three methods and time taken to fit models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-anchor",
   "metadata": {},
   "source": [
    "According to the result from task 5. The final accuracy is the same regarding any method, but the losses fluctuate a lot in `mini-batch` methood and fluctuate even more in the `stochastic` method.\n",
    "\n",
    "For the training time, `mini-batch` and `stochastic` take significant longer time than normal `batch` method, especially `stochastic`, one reason that could explaining this is we didn't exploit numpy's efficient vectorization operation much but instead use explicit for loop for every sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-visit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
